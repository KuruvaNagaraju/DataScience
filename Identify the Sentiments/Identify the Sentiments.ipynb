{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Sentiment analysis remains one of the key problems that has seen extensive application of natural language processing. This time around, given the tweets from customers about various tech firms who manufacture and sell mobiles, computers, laptops, etc, the task is to identify if the tweets have a negative sentiment towards such companies or products.\n",
    "\n",
    "![](https://datahack-prod.s3.ap-south-1.amazonaws.com/__sized__/contest_cover/sentiments_1920x480-thumbnail-1200x1200-90.jpg)\n",
    "\n",
    "Reference Link : https://datahack.analyticsvidhya.com/contest/linguipedia-codefest-natural-language-processing-1/#About"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary libraries.\n",
    "\n",
    "import numpy as np ## Numpy library for creating and modifying arrays.\n",
    "import pandas as pd ## Pandas library for reading '.csv' files as dataframes.\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize ## For sentence,word tokenizing.\n",
    "import re ## For regular expressions.\n",
    "import string ## For punctuations.\n",
    "from nltk.corpus import stopwords ## For stop words\n",
    "from nltk.stem.porter import PorterStemmer ## For getting root word.\n",
    "from spellchecker import SpellChecker ## For checking spelling of a word.\n",
    "from sklearn.model_selection import train_test_split ## For splitting data into train and validation.\n",
    "## from sklearn.feature_extraction.text import TfidfTransformer ## Converting text into numeric() \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer ## For converting text into tfidf vector(numeric array).\n",
    "import os ## For connecting to local machine to set path for reading files.\n",
    "from sklearn.naive_bayes import MultinomialNB ## For Naive bayes model.\n",
    "from time import time ## To get the processing time value. \n",
    "from sklearn.preprocessing import LabelEncoder ## For encoding the labels.\n",
    "from sklearn.metrics import accuracy_score ## For getting accuracy value.\n",
    "from sklearn.metrics import confusion_matrix,classification_report ## For confusion matrix and TNR,TPR,accuracy.\n",
    "from sklearn.model_selection import GridSearchCV ## For grid search\n",
    "from sklearn.pipeline import Pipeline ## For pipe line(to execute stpes sequecntially)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Python\\\\Pratice\\\\Identify the Sentiments'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get current working directory.\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\DataScience\\\\Pratice\\\\Identify the Sentiments'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set working directory.\n",
    "os.chdir(\"D:\\DataScience\\Pratice\\Identify the Sentiments\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load train and test data.\n",
    "train = pd.read_csv('train.csv',header='infer',sep=',',encoding='latin-1')\n",
    "test = pd.read_csv('test.csv',header='infer',sep=',',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7920, 3)\n",
      "(1953, 2)\n"
     ]
    }
   ],
   "source": [
    "## Check dimensions of train and test data.\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  #fingerprint #Pregnancy Test https://goo.gl/h1..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check first record of train data.\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>7920</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple Barcelona!!! #Apple #Store #BCN #Barcelo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label                                              tweet\n",
       "7919  7920      0  Apple Barcelona!!! #Apple #Store #BCN #Barcelo..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check last record of train data.\n",
    "train.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7921</td>\n",
       "      <td>I hate the new #iphone upgrade. Won't let me d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              tweet\n",
       "0  7921  I hate the new #iphone upgrade. Won't let me d..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check first record of test data.\n",
    "test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>9873</td>\n",
       "      <td>Finally I got it .. thanx my father .. #Samsun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              tweet\n",
       "1952  9873  Finally I got it .. thanx my father .. #Samsun..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check last record of test data.\n",
    "test.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7920.000000</td>\n",
       "      <td>7920.000000</td>\n",
       "      <td>7920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@architecture_3design - TAG YOUR FRIENDS @arch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3960.500000</td>\n",
       "      <td>0.255808</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2286.451399</td>\n",
       "      <td>0.436342</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1980.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3960.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5940.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7920.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id        label  \\\n",
       "count   7920.000000  7920.000000   \n",
       "unique          NaN          NaN   \n",
       "top             NaN          NaN   \n",
       "freq            NaN          NaN   \n",
       "mean    3960.500000     0.255808   \n",
       "std     2286.451399     0.436342   \n",
       "min        1.000000     0.000000   \n",
       "25%     1980.750000     0.000000   \n",
       "50%     3960.500000     0.000000   \n",
       "75%     5940.250000     1.000000   \n",
       "max     7920.000000     1.000000   \n",
       "\n",
       "                                                    tweet  \n",
       "count                                                7920  \n",
       "unique                                               7918  \n",
       "top     @architecture_3design - TAG YOUR FRIENDS @arch...  \n",
       "freq                                                    3  \n",
       "mean                                                  NaN  \n",
       "std                                                   NaN  \n",
       "min                                                   NaN  \n",
       "25%                                                   NaN  \n",
       "50%                                                   NaN  \n",
       "75%                                                   NaN  \n",
       "max                                                   NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get summary statistics of train data.\n",
    "train.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1953.000000</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Photo: a fake b!tch #thatstheshitidontlike #se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8897.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>563.926857</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7921.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8409.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8897.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9385.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9873.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                              tweet\n",
       "count   1953.000000                                               1953\n",
       "unique          NaN                                               1953\n",
       "top             NaN  Photo: a fake b!tch #thatstheshitidontlike #se...\n",
       "freq            NaN                                                  1\n",
       "mean    8897.000000                                                NaN\n",
       "std      563.926857                                                NaN\n",
       "min     7921.000000                                                NaN\n",
       "25%     8409.000000                                                NaN\n",
       "50%     8897.000000                                                NaN\n",
       "75%     9385.000000                                                NaN\n",
       "max     9873.000000                                                NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get summarry statistics of test data.\n",
    "test.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'label', 'tweet'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get train data column names.\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'tweet'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get test data column names.\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=7920, step=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get index range for train data.\n",
    "train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1953, step=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get index range for test data.\n",
    "test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        int64\n",
       "label     int64\n",
       "tweet    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get data types for train data columns.\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        int64\n",
       "tweet    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get data types for test data columns.\n",
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "label    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check null values for train data.\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check null  values for test data.\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Below method returns data types,levels,NA values,unique values for the given data frame.\n",
    "\n",
    "def getStatistics(df):\n",
    "    return pd.DataFrame({'dtypes' : df.dtypes,\n",
    "                         'levels' : [df[column].unique() for column in df.columns],\n",
    "                         'NA  Values' : df.isna().sum(),\n",
    "                         'Unique Values' :  df.nunique()\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtypes</th>\n",
       "      <th>levels</th>\n",
       "      <th>NA  Values</th>\n",
       "      <th>Unique Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>int64</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>0</td>\n",
       "      <td>7920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>int64</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <td>object</td>\n",
       "      <td>[#fingerprint #Pregnancy Test https://goo.gl/h...</td>\n",
       "      <td>0</td>\n",
       "      <td>7918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dtypes                                             levels  NA  Values  \\\n",
       "id      int64  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...           0   \n",
       "label   int64                                             [0, 1]           0   \n",
       "tweet  object  [#fingerprint #Pregnancy Test https://goo.gl/h...           0   \n",
       "\n",
       "       Unique Values  \n",
       "id              7920  \n",
       "label              2  \n",
       "tweet           7918  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get data types,levels,NA values,unique values for train data.\n",
    "getStatistics(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtypes</th>\n",
       "      <th>levels</th>\n",
       "      <th>NA  Values</th>\n",
       "      <th>Unique Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>int64</td>\n",
       "      <td>[7921, 7922, 7923, 7924, 7925, 7926, 7927, 792...</td>\n",
       "      <td>0</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <td>object</td>\n",
       "      <td>[I hate the new #iphone upgrade. Won't let me ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dtypes                                             levels  NA  Values  \\\n",
       "id      int64  [7921, 7922, 7923, 7924, 7925, 7926, 7927, 792...           0   \n",
       "tweet  object  [I hate the new #iphone upgrade. Won't let me ...           0   \n",
       "\n",
       "       Unique Values  \n",
       "id              1953  \n",
       "tweet           1953  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get data types,levels,NA values,unique values for test data.\n",
    "getStatistics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove URL from text.\n",
    "def remove_url(text):\n",
    "    url =  re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove html from text.\n",
    "def remove_html(text):\n",
    "    html = re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Emojis.\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "## Print punctuations from string class.\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove punctuatons.\n",
    "def remove_punctuation(text):\n",
    "    ## prepare a translation table to replace punctations with empty space.\n",
    "    translator = str.maketrans('','',string.punctuation)\n",
    "    ## replace punctations with empty space.\n",
    "    return text.translate(translator)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = \"wow! this works. \"\n",
    "#re.findall(\"\\w+\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a list of punctuation marks.\n",
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace punctuation marks with whitespace. \n",
    "def remove_special_characters(text):\n",
    "    text = str(text)\n",
    "    for punct in puncts:\n",
    "        if punct in text:\n",
    "            text = text.replace(punct, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd hfnj fje'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test remove_special_characters function.\n",
    "remove_special_characters('\"a\"bcd \"hfnj\" fje')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word tokenization.\n",
    "def word_tokenization(text):\n",
    "    return [w.lower() for w in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove stop words. \n",
    "def remove_stopWords(text):\n",
    "    sw = stopwords.words('english')\n",
    "    ## get the words which are not there in stop words and convert them into lower case\n",
    "    return [word.lower() for word in text if word.lower() not in sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stem/get root words for given text.\n",
    "def stemProcess(text):\n",
    "    ## instantiate PoterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(word) for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## install python spell check library (If you want install again then remove # in below statement)\n",
    "# !pip install pyspellchecker\n",
    "\n",
    "## Correct the spelling for the given text.\n",
    "def correct_spell(text):\n",
    "    ## instantiate spell checker\n",
    "    spell = SpellChecker()\n",
    "    correct_words = []\n",
    "    misspell_words = spell.unknown(text)\n",
    "    for word in text:\n",
    "        if word in misspell_words:\n",
    "            correct_words.append(spell.correction(word))\n",
    "        else:\n",
    "            correct_words.append(word)\n",
    "    return correct_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove stop words,url,html,emoji,punctuation and do stemming on Train data.\n",
    "train['tweet'] = train['tweet'].apply(remove_url)\n",
    "train['tweet'] = train['tweet'].apply(remove_html)\n",
    "train['tweet'] = train['tweet'].apply(remove_special_characters)\n",
    "train['tweet'] = train['tweet'].apply(word_tokenize)\n",
    "train['tweet'] = train['tweet'].apply(remove_stopWords)\n",
    "train['tweet'] = train['tweet'].apply(stemProcess)\n",
    "#train['tweet'] = train['tweet'].apply(correct_spell) ## checking spelling is taking too much time and accuracy wise, i didn't get much difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove stop words,url,html,emoji,punctuation and do stemming on Test data.\n",
    "test['tweet'] = test['tweet'].apply(remove_url)\n",
    "test['tweet'] = test['tweet'].apply(remove_html)\n",
    "test['tweet'] = test['tweet'].apply(remove_special_characters)\n",
    "test['tweet'] = test['tweet'].apply(word_tokenize)\n",
    "test['tweet'] = test['tweet'].apply(remove_stopWords)\n",
    "test['tweet'] = test['tweet'].apply(stemProcess)\n",
    "#test['tweet'] = test['tweet'].apply(correct_spell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'label', 'tweet'], dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get train data column names.\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set Index to train and test data.\n",
    "train.set_index('id',inplace=True)\n",
    "test.set_index('id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[fingerprint, pregnanc, test, android, app, be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                              tweet\n",
       "id                                                          \n",
       "1       0  [fingerprint, pregnanc, test, android, app, be..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get first record of train data.\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7921</th>\n",
       "      <td>[hate, new, iphon, upgrad, wont, let, download...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet\n",
       "id                                                     \n",
       "7921  [hate, new, iphon, upgrad, wont, let, download..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get first record of test data.\n",
    "test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split data into train and validation (80:20 format).\n",
    "\n",
    "train_text,valid_text,\\\n",
    "train_target,valid_target= train_test_split(train.drop('label',axis=1),train.drop('tweet',axis=1),\n",
    "                                          test_size=0.2,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7319</th>\n",
       "      <td>[ios8, brake, phone, appl, wont, except, seria...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet\n",
       "id                                                     \n",
       "7319  [ios8, brake, phone, appl, wont, except, seria..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get first record of train data.\n",
    "train_text.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6336, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check dimesions of train data.\n",
    "train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7319</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "id         \n",
       "7319      1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check first record of tran traget data.\n",
    "train_target.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3306</th>\n",
       "      <td>[moment, go, contact, isnt, number, iphon, updat]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet\n",
       "id                                                     \n",
       "3306  [moment, go, contact, isnt, number, iphon, updat]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check first record of validation data.\n",
    "valid_text.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3306</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "id         \n",
       "3306      1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check first record of validation target data.\n",
    "valid_target.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert list into string.\n",
    "def convertListToString(temp):\n",
    "    temp1 =[]\n",
    "    for i in temp:\n",
    "        temp1.append(i)\n",
    "    return \" \".join(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "7319    [ios8, brake, phone, appl, wont, except, seria...\n",
       "1925    [chorizo, appl, sausag, roll, made, nice, past...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check first 2 records of tweet column of train data.\n",
    "train_text['tweet'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert train tweet column data from list to string.\n",
    "train_text['tweet'] = train_text['tweet'].apply(convertListToString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert validation tweet column data from list to string.\n",
    "valid_text['tweet'] = valid_text['tweet'].apply(convertListToString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert test tweet column data from list to string.\n",
    "test['tweet'] = test['tweet'].apply(convertListToString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.782s.\n"
     ]
    }
   ],
   "source": [
    "## Instantiate TfidfVectorizer() with 1,2 grams.\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "#max_df=0.95, min_df=2, stop_words='english' #USE HELP TO SEE WHAT EACH DOES)\n",
    "\n",
    "## Get the start time.\n",
    "t0 = time()\n",
    "\n",
    "## Tokenize and build vocabulary for train,validation,test data.\n",
    "train_data  = tfidf_vectorizer.fit_transform(train_text['tweet'])\n",
    "validation_data = tfidf_vectorizer.transform(valid_text['tweet'])\n",
    "test_data =tfidf_vectorizer.transform(test['tweet'])\n",
    "\n",
    "## Print the process taken time.\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get vocabulary and idf values for tfidf vector.\n",
    "print(tfidf_vectorizer.vocabulary_)\n",
    "print(tfidf_vectorizer.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate label encoder.\n",
    "le_label = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nagar\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "## Do label encoding for train traget column data.\n",
    "train_target = le_label.fit_transform(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nagar\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "## Do label encoding for validation traget column data.\n",
    "valid_target = le_label.transform(valid_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6336, 60941)\n",
      "(6336,)\n"
     ]
    }
   ],
   "source": [
    "## Print dimesnions of train features,target columns data.\n",
    "print(train_data.shape)\n",
    "print(train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Instantiate Naive bayes and fit a model.\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(train_data, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get prediction on train and validation data.\n",
    "predict_train = naive_bayes.predict(train_data)\n",
    "predict_validation = naive_bayes.predict(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9455492424242424\n"
     ]
    }
   ],
   "source": [
    "## Display accuracy value for train data.\n",
    "print(\"Train Accuracy :\",accuracy_score(train_target,predict_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy : 0.8125\n"
     ]
    }
   ],
   "source": [
    "## Display  accuracy value for validation data.\n",
    "print(\"Validation Accuracy :\",accuracy_score(valid_target,predict_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4704   10]\n",
      " [ 335 1287]]\n"
     ]
    }
   ],
   "source": [
    "## Get confusion matrix for train data and display it.\n",
    "confusion_matrix_train = confusion_matrix(train_target,predict_train)\n",
    "print(confusion_matrix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1163   17]\n",
      " [ 280  124]]\n"
     ]
    }
   ],
   "source": [
    "## Get confusion matrix for validation data and display it.\n",
    "confusion_matrix_validation = confusion_matrix(valid_target, predict_validation)\n",
    "print(confusion_matrix_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TNR:  0.9978786593126856\n",
      "\n",
      "\n",
      "Train TPR:  0.7934648581997534\n",
      "\n",
      "\n",
      "Train Accuracy:  0.9455492424242424\n"
     ]
    }
   ],
   "source": [
    "Accuracy_Train=(confusion_matrix_train[0,0]+confusion_matrix_train[1,1])/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1]+confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "TNR_Train= confusion_matrix_train[0,0]/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1])\n",
    "TPR_Train= confusion_matrix_train[1,1]/(confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "\n",
    "print(\"Train TNR: \",TNR_Train)\n",
    "print(\"\\n\")\n",
    "print(\"Train TPR: \",TPR_Train)\n",
    "print(\"\\n\")\n",
    "print(\"Train Accuracy: \",Accuracy_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation TNR:  0.985593220338983\n",
      "\n",
      "\n",
      "Validation TPR:  0.3069306930693069\n",
      "\n",
      "\n",
      "Validation Accuracy:  0.8125\n"
     ]
    }
   ],
   "source": [
    "Accuracy_Test=(confusion_matrix_validation[0,0]+confusion_matrix_validation[1,1])/(confusion_matrix_validation[0,0]+confusion_matrix_validation[0,1]+confusion_matrix_validation[1,0]+confusion_matrix_validation[1,1])\n",
    "TNR_Test= confusion_matrix_validation[0,0]/(confusion_matrix_validation[0,0] +confusion_matrix_validation[0,1])\n",
    "TPR_Test= confusion_matrix_validation[1,1]/(confusion_matrix_validation[1,0] +confusion_matrix_validation[1,1])\n",
    "\n",
    "print(\"Validation TNR: \",TNR_Test)\n",
    "print(\"\\n\")\n",
    "print(\"Validation TPR: \",TPR_Test)\n",
    "print(\"\\n\")\n",
    "print(\"Validation Accuracy: \",Accuracy_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copy test data ino temp.\n",
    "temp = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the predictions on test data.\n",
    "y_pred = naive_bayes.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get original values of preidctions.\n",
    "temp['label'] = le_label.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reset index.\n",
    "temp.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copy id,label columns from temp to to_submit.\n",
    "to_submit = temp[['id', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1768\n",
       "1     185\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the value count for label column.\n",
    "to_submit.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1953, 2)\n",
      "(1953, 1)\n"
     ]
    }
   ],
   "source": [
    "## Print dimensions of t-_submit,test data.\n",
    "print(to_submit.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## store to_submit into csv file with name NaiveBayes.\n",
    "to_submit.to_csv('NaiveBayes.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## with Grid Search Naive Bayes Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare parameters dictionary for grid search. \n",
    "param_grid = [{'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "               'vect__use_idf': [True, False],\n",
    "               'vect__norm': ['l1', 'l2'],\n",
    "               'nb_clf__alpha': [1, 1e-1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add tifidf vectorizer,naive bayes models to Pipeline.\n",
    "nb_tfidf = Pipeline([('vect', tfidf_vectorizer), \n",
    "                     ('nb_clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build grid search model.\n",
    "gs_nb_tfidf = GridSearchCV(nb_tfidf,  ## Pipeline to execute tfidf,naive bayes.\n",
    "                           param_grid, ## Parameters dictionary.\n",
    "                           scoring='accuracy', ## Metric on which we want to calculate.\n",
    "                           cv=5,  ### Number of cross folds.\n",
    "                           verbose=2, ## To display each process steps.\n",
    "                           n_jobs=1) ## To use all processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.3s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.1s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.1s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.1s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.6s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.6s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.6s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.4s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.6s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.6s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.4s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   0.9s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   0.9s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   0.9s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   0.9s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   0.9s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   0.9s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   0.9s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.9s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.7s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.9s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   0.9s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   0.9s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   0.9s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   0.9s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l1, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=True, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 1), vect__norm=l2, vect__use_idf=False, total=   0.2s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.6s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.6s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.4s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.6s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.6s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.6s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l1, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.6s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.6s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 2), vect__norm=l2, vect__use_idf=False, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   1.0s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   0.9s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   0.9s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   0.9s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=True, total=   0.9s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.9s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.9s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.9s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l1, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   0.9s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   1.0s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   0.7s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   0.5s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   0.9s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=True, total=   0.9s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   0.8s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   0.9s\n",
      "[CV] nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False \n",
      "[CV]  nb_clf__alpha=0.1, vect__ngram_range=(1, 3), vect__norm=l2, vect__use_idf=False, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_acc...\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('nb_clf',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=1,\n",
       "             param_grid=[{'nb_clf__alpha': [1, 0.1],\n",
       "                          'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                          'vect__norm': ['l1', 'l2'],\n",
       "                          'vect__use_idf': [True, False]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fit a model.\n",
    "gs_nb_tfidf.fit(train_text['tweet'], train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'nb_clf__alpha': 0.1, 'vect__ngram_range': (1, 2), 'vect__norm': 'l2', 'vect__use_idf': False} \n"
     ]
    }
   ],
   "source": [
    "## Display best parameters.\n",
    "print('Best parameter set: %s ' % gs_nb_tfidf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.894\n"
     ]
    }
   ],
   "source": [
    "## Get accuray for train data.\n",
    "print('CV Accuracy: %.3f' % gs_nb_tfidf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get best parameters.\n",
    "nb_clf = gs_nb_tfidf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.885\n"
     ]
    }
   ],
   "source": [
    "## Get and display accuracy for validation data.\n",
    "print('Validation Accuracy: %.3f' % nb_clf.score(valid_text['tweet'], valid_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get predictions for test data.\n",
    "test_predictions = gs_nb_tfidf.predict(test['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Display test prediction values.\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get original values of test predictions.\n",
    "test['label'] = le_label.inverse_transform(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reset index for test data.\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copy id,label columns data from test to to_submit.\n",
    "to_submit = test[['id', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1451\n",
       "1     502\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get value counts for label column.\n",
    "to_submit.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1953, 2)\n",
      "(1953, 1)\n"
     ]
    }
   ],
   "source": [
    "## Display to_submit,test dimesnions.\n",
    "print(to_submit.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Store to_submit into csv file with name NaiveBayes_GridSearch. \n",
    "to_submit.to_csv('NaiveBayes_GridSearch.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
