import streamlit as st
import os
import shutil
import logging

from vectorstore import create_vector_db
from rag_chain import run_rag
from llm_config import query_vllm
from file_handler import save_and_load_pdf_pagewise
from summary_chain import run_summary

# ----------------------------------------
# Configure logging
# ----------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s]: %(message)s",
    handlers=[logging.FileHandler("app.log"), logging.StreamHandler()]
)

class ResumeAnalyzerApp:
    """
    Streamlit application for analyzing resumes using RAG (Retrieval-Augmented Generation).
    Provides summary and Q&A capabilities over uploaded resumes.
    """

    def __init__(self):
        """Initialize session state variables."""
        self.setup_page()

    def setup_page(self):
        """Configure Streamlit page layout and title."""
        st.set_page_config(page_title="RAG App", layout="wide")
        st.title("üìÑ Candidate Resume Analyzer with Q&A")

    def handle_file_upload(self):
        """
        Handle PDF resume uploads from user.
        Returns:
            list: Uploaded PDF files.
        """
        return st.file_uploader("Upload a Resume (PDF)", type=["pdf"], accept_multiple_files=True)

    def process_uploaded_files(self, uploaded_files):
        """
        Process uploaded PDF files: convert, create vector DB, and generate summary.
        Args:
            uploaded_files (list): List of uploaded file objects.
        """
        try:
            with st.spinner("Processing resume..."):
                raw_docs = save_and_load_pdf_pagewise(uploaded_files)
                st.session_state.raw_docs = raw_docs

                # Delete existing DB and recreate
                if os.path.exists("chroma_db"):
                    shutil.rmtree("chroma_db")
                    logging.info("Deleted old Chroma DB.")
                    st.info("Old vector DB deleted.")

                create_vector_db(raw_docs)
                logging.info("New vector DB created.")
                st.success("Resume Vector DB created successfully.")

                summary = run_summary(raw_docs)
                st.session_state.summary_text = summary['answer']

        except Exception as e:
            logging.error(f"Error processing uploaded files: {e}")
            st.error("Failed to process the uploaded resumes.")

    def display_summary(self):
        """Display the resume summary generated by the language model."""
        st.subheader("üìå Summary")
        st.write(st.session_state.summary_text)

    def ask_questions(self):
        """Provide interface for users to ask questions about the resume."""
        st.subheader("üí¨ Ask Questions About the Candidate")

        if "chat_history" not in st.session_state:
            st.session_state.chat_history = []

        user_question = st.text_input(
            "Ask something like 'What is total year of experience'", 
            key="user_input"
        )

        if user_question:
            try:
                with st.spinner("Analyzing resume..."):
                    result = run_rag(user_question)
                    answer = result["answer"]
                    sources = result["sources"]

                    st.session_state.chat_history.append({
                        "question": user_question,
                        "answer": answer
                    })

                # Display response
                st.write(f"**Answer:** {answer}")
                with st.expander("üîç Supporting Resume Excerpts"):
                    for i, doc in enumerate(sources):
                        st.markdown(f"**Source {i+1}**: {doc.page_content}")

            except Exception as e:
                logging.error(f"Error during question answering: {e}")
                st.error("Failed to get an answer. Please try again.")

    def show_chat_history(self):
        """Display past Q&A interactions."""
        if st.session_state.get("chat_history"):
            st.subheader("üïò Chat History")
            for chat in reversed(st.session_state.chat_history):
                st.markdown(f"**You:** {chat['question']}")
                st.markdown(f"**AI:** {chat['answer']}")

    def run(self):
        """Main entry point to run the Streamlit app."""
        uploaded_files = self.handle_file_upload()

        # Only process files once
        if uploaded_files and "raw_docs" not in st.session_state:
            self.process_uploaded_files(uploaded_files)

        if "summary_text" in st.session_state:
            self.display_summary()
            self.ask_questions()
            self.show_chat_history()


# ----------------------------------------
# Run the app
# ----------------------------------------
if __name__ == "__main__":
    try:
        app = ResumeAnalyzerApp()
        app.run()
    except Exception as main_error:
        logging.critical(f"Fatal error in main app: {main_error}")
        st.error("Unexpected error occurred. Please check logs.")
